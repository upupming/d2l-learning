{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0d87b76f1af467fd3f493e429fbbcf63b2a04674deb17aebee11ad67a1a0c6c4d",
   "display_name": "Python 3.9.2 64-bit ('py3.9': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "尝试自己实现 Conv2d，支持多通道输入和输出。\n",
    "\n",
    "网上已经有人给出相应的实现：https://discuss.pytorch.org/t/how-was-conv2d-implemented-in-pytorch/35223/2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "weight torch.Size([2, 3, 4, 5])\nbias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 先来看看 Conv2d 的参数的结构\n",
    "conv2d = nn.Conv2d(3, 2, (4, 5))\n",
    "\n",
    "for name, param in conv2d.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 2, 7, 8])\ntensor([[[[ 4.0505e+00,  5.0768e+00,  1.1193e+01,  9.3357e+00,  3.5201e+00,\n           -2.8899e+00,  1.4229e+01,  8.7867e+00],\n          [-1.1399e+00, -2.2456e+00, -3.3975e+00, -4.6363e+00,  8.5825e+00,\n           -9.6571e+00,  3.9503e+00,  6.7593e+00],\n          [ 1.0994e+01, -9.8126e+00,  3.2591e+00,  8.9945e+00,  1.6969e+01,\n           -1.2465e+01,  5.9345e+00,  4.1210e-01],\n          [-5.0153e+00, -4.2659e+00, -4.0778e+00, -1.4153e+00, -1.4689e+00,\n            8.3639e+00, -4.6947e+00,  5.1888e+00],\n          [-1.0983e+00, -4.7729e+00, -1.3250e+00, -1.1528e+01, -8.8684e+00,\n            4.0537e+00,  3.2212e+00,  4.2422e+00],\n          [ 1.3402e+00, -2.8066e+00, -4.1240e-01,  5.5571e+00,  3.6924e+00,\n           -3.3545e+00, -6.2308e+00,  1.2915e+01],\n          [-1.8232e+00,  1.3599e+01,  1.2224e+01,  3.6629e+00,  4.4683e+00,\n            8.0019e+00,  5.2227e+00, -4.4041e+00]],\n\n         [[ 5.0802e+00,  3.6428e+00, -1.7184e+00, -1.0121e-01,  1.1512e+01,\n           -2.3624e+00,  8.4330e+00,  1.2408e+01],\n          [-4.5292e+00, -1.2684e+01, -7.4149e+00,  4.1364e+00, -3.9972e+00,\n           -1.3982e+01,  1.6039e+00, -6.5720e+00],\n          [-7.7785e+00,  4.7614e+00, -3.5036e+00,  2.8796e+00,  5.8449e+00,\n           -8.7853e+00,  4.6104e+00,  6.5575e+00],\n          [-5.4963e+00,  4.3230e+00,  2.0848e+00,  4.0148e+00,  6.9160e-01,\n            2.1421e+00,  1.4384e+00,  2.4047e+00],\n          [ 2.6974e+00, -8.4109e+00, -2.4350e+00,  7.3843e+00, -4.8207e+00,\n           -2.7589e+00,  1.0189e+01,  1.6171e+00],\n          [ 6.3206e+00,  6.7910e+00, -8.0121e-01,  3.7719e+00,  3.0435e+00,\n           -9.8558e-01, -3.4930e+00, -3.4588e+00],\n          [-6.7794e-03,  9.3651e-01,  8.0907e+00, -5.4491e+00, -4.4531e+00,\n            1.8872e+00,  2.1565e+00,  2.6890e+00]]]],\n       grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Batch * Channels * Height * width\n",
    "X = torch.randn(1, 3, 10, 12)\n",
    "\n",
    "# 观察上面的输出，conv2d.weight 的维度分别是 [out_channels, in_channels, kernel_height, kernel_wdith]\n",
    "# weight for conv2d: out\n",
    "w = nn.Parameter(torch.randn(2, 3, 4, 5))\n",
    "\n",
    "# 将我们自己初始化的参数给卷积层的参数赋值\n",
    "conv2d.weight = w\n",
    "conv2d.bias = nn.Parameter(torch.zeros(2))\n",
    "Y = conv2d(X)\n",
    "print(Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 60, 56])\n"
     ]
    }
   ],
   "source": [
    "# 下面尝试手写自己的实现\n",
    "X_unf = nn.functional.unfold(X, (4, 5))\n",
    "print(X_unf.shape)\n",
    "# 输出维度 (N, C * pord(kernel_size), prod(out_img_size))\n",
    "# 第 2 维表示每个 block 有多少个值，第 3 维则表示有多少个 block，每个 block 都是 kernel_size 大小的（这里的 4*5），有多少个 block 就是说有多少个输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1 * 56 * 60] * [60 * 2] = [1 * 56 * 2] -> [1 * 2 * 56]\n",
    "Y_unf = X_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "Y1 = nn.functional.fold(Y_unf, (7, 8), (1, 1))\n",
    "# 也可以直接 reshape 就行\n",
    "# Y = Y_unf.reshape(1, 2, 7, 8)\n",
    "\n",
    "assert((Y - Y1).sum().abs() < 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(3.8147e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((torch.nn.functional.conv2d(X) - Y1).abs().max())"
   ]
  }
 ]
}